% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gamlss_fix.R
\name{ba.control}
\alias{ba.control}
\title{Functions from gamlss/gamlss.add with bugs fixed}
\usage{
ba.control(
  offset = NULL,
  method = "fREML",
  control = list(),
  select = FALSE,
  scale = 0,
  gamma = 1,
  knots = NULL,
  sp = NULL,
  min.sp = NULL,
  paraPen = NULL,
  chunk.size = 10000,
  rho = 0,
  AR.start = NULL,
  discrete = TRUE,
  cluster = NULL,
  nthreads = 2,
  gc.level = 1,
  use.chol = FALSE,
  samfrac = 1,
  coef = NULL,
  drop.unused.levels = TRUE,
  drop.intercept = NULL,
  ...
)
}
\arguments{
\item{offset}{The offset in the formula.}

\item{method}{The method argument in \code{bam()}.}

\item{control}{A list of fit control parameters to replace defaults returned by gam.control. Any control parameters not supplied stay at their default values.}

\item{select}{The \code{select} argument in \code{bam()}. Determine should selection penalties be added to the smooth effects, so that they can in principle be penalized out of the model.}

\item{scale}{For the scale parameter. If this is positive then it is taken as the known scale parameter. Negative signals that the scale paraemter is unknown. 0 signals that the scale parameter is 1 for Poisson and binomial and unknown otherwise.}

\item{gamma}{The \code{gamma} argument in \code{bam()}. Increase above 1 to force smoother fits.}

\item{knots}{The \code{knots} argument in \code{bam()}. An optional list containing user specified knot values to be used for basis construction.}

\item{sp}{The \code{sp} argument in \code{bam()}. A vector of smoothing parameters can be provided here.}

\item{min.sp}{The \code{min.sp} argument in \code{bam()}. Lower bounds can be supplied for the smoothing parameters.}

\item{paraPen}{The \code{paraPen} argument in \code{bam()}. Optional list specifying any penalties to be applied to parametric model terms.}

\item{chunk.size}{The model matrix is created in chunks of this size, rather than ever being formed whole.}

\item{rho}{An AR1 error model can be used for the residuals (based on dataframe order), of Gaussian-identity link models. This is the AR1 correlation parameter.}

\item{AR.start}{Logical variable of same length as data, \code{TRUE} at first observation of an independent section of AR1 correlation.}

\item{discrete}{With \code{method="fREML"} it is possible to discretize covariates for storage and efficiency reasons. If \code{discrete} is \code{TRUE}, a number or a vector of numbers for each smoother term, then discretization happens. If numbers are supplied they give the number of discretization bins.}

\item{cluster}{\code{bam} can compute the computationally dominant QR decomposition in parallel using parLapply from the \code{parallel} package, if it is supplied with a cluster on which to do this (a cluster here can be some cores of a single machine).}

\item{nthreads}{Number of threads to use for non-cluster computation (e.g. combining results from cluster nodes).}

\item{gc.level}{To keep the memory footprint down, it can help to call the garbage collector often, but this takes a substatial amount of time. Setting this to zero means that garbage collection only happens when R decides it should. Setting to 2 gives frequent garbage collection. 1 is in between.}

\item{use.chol}{By default \code{bam} uses a very stable QR update approach to obtaining the QR decomposition of the model matrix. For well conditioned models an alternative accumulates the crossproduct of the model matrix and then finds its Choleski decomposition, at the end. This is somewhat more efficient, computationally.}

\item{samfrac}{For very large sample size Generalized additive models the number of iterations needed for the model fit can be reduced by first fitting a model to a random sample of the data, and using the results to supply starting values. This initial fit is run with sloppy convergence tolerances, so is typically very low cost. \code{samfrac} is the sampling fraction to use. 0.1 is often reasonable.}

\item{coef}{Initial values for model coefficients.}

\item{drop.unused.levels}{By default unused levels are dropped from factors before fitting. For some smooths involving factor variables you might want to turn this off.}

\item{drop.intercept}{Set to \code{TRUE} to force the model to really not have the a constant in the parametric model part, even with factor variables present.}

\item{...}{Other arguments.}
}
\value{
A control object
}
\description{
The control for \code{ba()}. From \code{gamlss.add::ba.control()} and \code{gamlss::bam()}.
}
\section{ba.control}{
NA
}

